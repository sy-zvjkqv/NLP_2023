{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertJapaneseTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from transformers import BertJapaneseTokenizer, BertForMaskedLM\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification,AdamW, BertConfig, BertModel, BertPreTrainedModel\n",
    "import pytorch_lightning as pl\n",
    "#MODEL_NAME='bert-base-cased'\n",
    "from torch import nn\n",
    "import MeCab\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "batch=2\n",
    "model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained(model_name)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "tagger = MeCab.Tagger()\n",
    "tokenizer = BertTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58080/2688398077.py:1: DtypeWarning: Columns (7,9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  UserTweets = pd.read_csv(\"/home/is/shuntaro-o/dev/persons_move_analysis/data/20210_1month_per_hour/202210_1month_per_hour_ad_estimate.csv\")\n"
     ]
    }
   ],
   "source": [
    "UserTweets = pd.read_csv(\"/home/is/shuntaro-o/dev/persons_move_analysis/data/20210_1month_per_hour/202210_1month_per_hour_ad_estimate.csv\")\n",
    "UserPlase = pd.read_csv('/home/is/shuntaro-o/dev/disaster_analysis_Twitter/data/TweetPlaces_Japan7Cities/FoursquareUserPlacesTokyo_20210419.txt', sep=',', lineterminator='\\n', header=None,names = ['place_id', 'city_name', 'object', 'country', 'UserPlase_longitude', 'UserPlase_latitude', 'UserPlase_sub_longitude', 'UserPlase_sub_latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserTweets = UserTweets.iloc[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserPlase =UserPlase[~UserPlase.duplicated(subset='place_id')]\n",
    "UserPlase = UserPlase.reset_index(drop=True)\n",
    "UserTweets = UserTweets.reset_index(drop=True)\n",
    "merged_Tweet_place = pd.merge(UserTweets , UserPlase, how='left', on = \"place_id\")\n",
    "merged_Tweet_place = merged_Tweet_place.reset_index(drop=True)\n",
    "merged_Tweet_place = merged_Tweet_place.dropna(subset=['UserPlase_latitude','UserPlase_longitude'])\n",
    "def UTM_cal(lat,lon):\n",
    "    p,a=divmod(lat*60,40)\n",
    "    q,b=divmod(a,5)\n",
    "    r,c=divmod(b*60,30)\n",
    "    s,d=divmod(c,15)\n",
    "    t,e=divmod(d,7.5)\n",
    "\n",
    "    u=str(lon-100)[0:2]\n",
    "    f=lon-int(u)-100\n",
    "    v,g=divmod(f*60,7.5)\n",
    "    w,h=divmod(g*60,45)\n",
    "    x,i=divmod(h,22.5)\n",
    "    y,j=divmod(i,11.25)\n",
    "\n",
    "    m=(s*2)+(x+1)\n",
    "    n=(t*2)+(y+1)\n",
    "    p=int(p)\n",
    "    u=int(u)\n",
    "    q=int(q)\n",
    "    v=int(v)\n",
    "    r=int(r)\n",
    "    w=int(w)\n",
    "    m=int(m)\n",
    "    n=int(n)\n",
    "\n",
    "    ans=str(p)+str(u)+str(q)+str(v)\n",
    "    ans=int(ans)\n",
    "    return(ans)\n",
    "code_list=[]\n",
    "for index, r in merged_Tweet_place.iterrows():\n",
    "    ans=UTM_cal(r.UserPlase_latitude,r.UserPlase_longitude)\n",
    "    code_list.append(ans)\n",
    "merged_Tweet_place = merged_Tweet_place.reset_index(drop=True)\n",
    "code_list=pd.Series(code_list)\n",
    "merged_Tweet_place=pd.concat([merged_Tweet_place,code_list],axis=1)\n",
    "merged_Tweet_place=merged_Tweet_place.rename(columns={0: 'code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/is/shuntaro-o/dev/persons_move_analysis/data/202271month_per_hour_geotaged_adGeocode_Tokyo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"code\"\n",
    "L = LabelEncoder()\n",
    "df[y] = L.fit_transform(df[y])\n",
    "num_class = df[y].max() + 1  # ã‚ªãƒªã‚¸ãƒ³ã®è£œæ­£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel\n",
    "from transformers import BertModel\n",
    "class BertForSequenceClassifier_pl(pl.LightningModule):\n",
    "        \n",
    "    def __init__(self, model_name, lr, num_class):\n",
    "        # model_name: Transformersã®ãƒ¢ãƒ‡ãƒ«ã®åå‰\n",
    "        # num_labels: ãƒ©ãƒ™ãƒ«ã®æ•°\n",
    "        # lr: å­¦ç¿’ç‡\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        # å¼•æ•°ã®num_labelsã¨lrã‚’ä¿å­˜ã€‚\n",
    "        # ä¾‹ãˆã°ã€self.hparams.lrã§lrã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã€‚\n",
    "        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆæ™‚ã«ã‚‚è‡ªå‹•ã§ä¿å­˜ã•ã‚Œã‚‹ã€‚\n",
    "        self.save_hyperparameters() \n",
    "\n",
    "        # BERTã®ãƒ­ãƒ¼ãƒ‰\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_class)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # BertLayerãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æœ€å¾Œã‚’å‹¾é…è¨ˆç®—ã‚ã‚Šã«å¤‰æ›´\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.bert.encoder.layer[-1].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        preds= self.classifier(output.pooler_output)\n",
    "        \n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(preds, labels)\n",
    "        #print(f\"tihi is {loss}\")\n",
    "        return loss, preds\n",
    "    \n",
    "       # trainã®ãƒŸãƒ‹ãƒãƒƒãƒã«å¯¾ã—ã¦è¡Œã†å‡¦ç†\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, preds = self.forward(input_ids=batch[\"input_ids\"],\n",
    "                                    attention_mask=batch[\"attention_mask\"],\n",
    "                                    labels=batch[\"labels\"])\n",
    "        self.log('train_loss', loss)\n",
    "        return {'loss': loss,\n",
    "                'batch_preds': preds,\n",
    "                'batch_labels': batch[\"labels\"]}\n",
    "\n",
    "    # validationã€testã§ã‚‚train_stepã¨åŒã˜å‡¦ç†ã‚’è¡Œã†\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, preds = self.forward(input_ids=batch[\"input_ids\"],\n",
    "                                    attention_mask=batch[\"attention_mask\"],\n",
    "                                    labels=batch[\"labels\"])\n",
    "        return {'loss': loss,\n",
    "                'batch_preds': preds,\n",
    "                'batch_labels': batch[\"labels\"]}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, preds = self.forward(input_ids=batch[\"input_ids\"],\n",
    "                                    attention_mask=batch[\"attention_mask\"],\n",
    "                                    labels=batch[\"labels\"])\n",
    "        return {'loss': loss,\n",
    "                'batch_preds': preds,\n",
    "                'batch_labels': batch[\"labels\"]}\n",
    "\n",
    "    # epochçµ‚äº†æ™‚ã«validationã®lossã¨accuracyã‚’è¨˜éŒ²\n",
    "    def validation_epoch_end(self, outputs, mode=\"val\"):\n",
    "        # lossè¨ˆç®—\n",
    "        epoch_preds = torch.cat([x['batch_preds'] for x in outputs])\n",
    "        epoch_labels = torch.cat([x['batch_labels'] for x in outputs])\n",
    "        epoch_loss = self.criterion(epoch_preds, epoch_labels)\n",
    "        self.log(f\"{mode}_loss\", epoch_loss, logger=True)\n",
    "\n",
    "        num_correct = (epoch_preds.argmax(dim=1) == epoch_labels).sum().item()\n",
    "        epoch_accuracy = num_correct / len(epoch_labels)\n",
    "        self.log(f\"{mode}_accuracy\", epoch_accuracy, logger=True)\n",
    "\n",
    "        \n",
    "\n",
    "    # testãƒ‡ãƒ¼ã‚¿ã®lossã¨accuracyã‚’ç®—å‡ºï¼ˆvalidationã®ä½¿ã„ã¾ã‚ã—ï¼‰\n",
    "    def test_epoch_end(self, outputs):\n",
    "        return self.validation_epoch_end(outputs, \"test\")\n",
    "\n",
    "    # å­¦ç¿’ã«ç”¨ã„ã‚‹ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã‚’è¿”ã™é–¢æ•°ã‚’æ›¸ãã€‚\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = '/home/is/shuntaro-o/dev/persons_move_analysis/models/Tokyo_model_ver2.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Tokyo = merged_Tweet_place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58080/2582238918.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_Tokyo[x] = df_Tokyo[x].str.replace(r'[ã€ã€‘]', ' ')       # ã€ã€‘ã®é™¤å»\n",
      "/tmp/ipykernel_58080/2582238918.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_Tokyo[x] = df_Tokyo[x].str.replace(r'[ï¼ˆï¼‰()]', ' ')     # ï¼ˆï¼‰ã®é™¤å»\n",
      "/tmp/ipykernel_58080/2582238918.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_Tokyo[x] = df_Tokyo[x].str.replace(r'[ï¼»ï¼½\\[\\]]', ' ')   # ï¼»ï¼½ã®é™¤å»\n",
      "/tmp/ipykernel_58080/2582238918.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_Tokyo[x] = df_Tokyo[x].str.replace(r'[@ï¼ ]\\w+', '')  # ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã®é™¤å»\n",
      "/tmp/ipykernel_58080/2582238918.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_Tokyo[x] = df_Tokyo[x].str.replace(r'https?:\\/\\/.*?[\\r\\n ]', '')  # URLã®é™¤å»\n",
      "/tmp/ipykernel_58080/2582238918.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_Tokyo[x] = df_Tokyo[x].str.replace(r'http:\\/\\/.*?[\\r\\n ]', '')  # URLã®é™¤å»\n"
     ]
    }
   ],
   "source": [
    "x = \"text\"\n",
    "df_Tokyo[x] = df_Tokyo[x].astype(str)\n",
    "df_Tokyo[x]=df_Tokyo[x].astype(str)\n",
    "df_Tokyo[x] = df_Tokyo[x].str.replace(r'[ã€ã€‘]', ' ')       # ã€ã€‘ã®é™¤å»\n",
    "df_Tokyo[x] = df_Tokyo[x].str.replace(r'[ï¼ˆï¼‰()]', ' ')     # ï¼ˆï¼‰ã®é™¤å»\n",
    "df_Tokyo[x] = df_Tokyo[x].str.replace(r'[ï¼»ï¼½\\[\\]]', ' ')   # ï¼»ï¼½ã®é™¤å»\n",
    "df_Tokyo[x] = df_Tokyo[x].str.replace(r'[@ï¼ ]\\w+', '')  # ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã®é™¤å»\n",
    "df_Tokyo[x]= df_Tokyo[x].str.replace(r'_', '')#underscodf_Tokyo[x].str \n",
    "df_Tokyo[x] = df_Tokyo[x].str.replace(r'https?:\\/\\/.*?[\\r\\n ]', '')  # URLã®é™¤å»\n",
    "df_Tokyo[x] = df_Tokyo[x].str.replace(r'http:\\/\\/.*?[\\r\\n ]', '')  # URLã®é™¤å»\n",
    "df_Tokyo[x] = df_Tokyo[x].str.replace(r'ã€€', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "sentences_text_test=df_Tokyo.text.values\n",
    "list_estimate = []\n",
    "model = BertForSequenceClassifier_pl.load_from_checkpoint(best_model_path)\n",
    "bert=model.bert.cuda()\n",
    "classifier=model.classifier.cuda()\n",
    "for sentence in sentences_text_test:\n",
    "    encoding = tokenizer(\n",
    "    sentence,\n",
    "    padding = 'longest',\n",
    "    return_tensors='pt')\n",
    "    encoding = { k: v.cuda() for k, v in encoding.items() }\n",
    "    with torch.no_grad():\n",
    "        output = bert(**encoding)\n",
    "        ans=classifier(output.pooler_output)\n",
    "        ans = ans.to('cpu').detach().numpy().copy()\n",
    "        ans = ans.argmax()\n",
    "        ans = L.inverse_transform([ans])[0]\n",
    "        list_estimate.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_estimate=pd.Series(list_estimate)\n",
    "df_Tokyo = df_Tokyo.reset_index(drop=True)\n",
    "df_Tokyo_adEstimate=pd.concat([df_Tokyo,list_estimate],axis=1)\n",
    "df_Tokyo_adEstimate=df_Tokyo_adEstimate.rename(columns={0: 'Tokyo_code_estimate'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>place_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>...</th>\n",
       "      <th>author_location</th>\n",
       "      <th>city_name</th>\n",
       "      <th>object</th>\n",
       "      <th>country</th>\n",
       "      <th>UserPlase_longitude</th>\n",
       "      <th>UserPlase_latitude</th>\n",
       "      <th>UserPlase_sub_longitude</th>\n",
       "      <th>UserPlase_sub_latitude</th>\n",
       "      <th>code</th>\n",
       "      <th>Tokyo_code_estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ãã‚Œã‚‚è‰¯ã„ã‘ã©ãƒ­ãƒªãƒ‡è¡Œã“ã†ã‚ˆğŸ°ğŸ‘—ğŸ¤´ğŸ‘¸</td>\n",
       "      <td>2022-10-01_00:59:57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>65b41c11aca77bdb</td>\n",
       "      <td>4843678447</td>\n",
       "      <td>...</td>\n",
       "      <td>ãƒ‡ã‚£ã‚ºãƒ‹ãƒ¼ãƒ©ãƒ³ãƒ‰è¿‘è¾º</td>\n",
       "      <td>åƒè‘‰ æµ¦å®‰å¸‚</td>\n",
       "      <td>city</td>\n",
       "      <td>æ—¥æœ¬</td>\n",
       "      <td>139.872407</td>\n",
       "      <td>35.616612</td>\n",
       "      <td>139.939631</td>\n",
       "      <td>35.672793</td>\n",
       "      <td>533936</td>\n",
       "      <td>533945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>å„ªè‰¯ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã•ã‚“ğŸ¥‡</td>\n",
       "      <td>2022-10-01_00:59:54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>f1299e526e0cc34d</td>\n",
       "      <td>1312247388745023488</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>åƒè‘‰ ä½å€‰å¸‚</td>\n",
       "      <td>city</td>\n",
       "      <td>æ—¥æœ¬</td>\n",
       "      <td>140.126120</td>\n",
       "      <td>35.624589</td>\n",
       "      <td>140.301034</td>\n",
       "      <td>35.766545</td>\n",
       "      <td>534031</td>\n",
       "      <td>533934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ã“ã“æœ€è¿‘ãšã£ã¨ãƒã‚¬ãƒ†ã‚£ãƒ–ã¨ãƒã‚¸ãƒ†ã‚£ãƒ–ãŒæˆ¦ã£ã¦ã¦ã€ã‚„ã£ã¨ãƒã‚¸ãƒ†ã‚£ãƒ–ãŒå‹ã¡ã‚‚ã†ã—ãŸï¼æ‹æ‰‹ï¼</td>\n",
       "      <td>2022-10-01_00:59:53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>77173905596af4ab</td>\n",
       "      <td>449521349</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>æ±äº¬ æ–‡äº¬åŒº</td>\n",
       "      <td>city</td>\n",
       "      <td>æ—¥æœ¬</td>\n",
       "      <td>139.717275</td>\n",
       "      <td>35.699474</td>\n",
       "      <td>139.772477</td>\n",
       "      <td>35.735929</td>\n",
       "      <td>533945</td>\n",
       "      <td>533945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>æœ‰è­˜è€…ãŒæ•™ãˆã¦ãã‚ŒãŸã‚‰ã„ã„ãªãw</td>\n",
       "      <td>2022-10-01_00:59:52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4c1c4868f96634ed</td>\n",
       "      <td>1060387314369683456</td>\n",
       "      <td>...</td>\n",
       "      <td>æ±äº¬</td>\n",
       "      <td>æ±äº¬ æ±Ÿæ±åŒº</td>\n",
       "      <td>city</td>\n",
       "      <td>æ—¥æœ¬</td>\n",
       "      <td>139.771307</td>\n",
       "      <td>35.582057</td>\n",
       "      <td>139.849007</td>\n",
       "      <td>35.708066</td>\n",
       "      <td>533926</td>\n",
       "      <td>533934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>ã”ç„¡äº‹ã§ä½•ã‚ˆã‚Šã§ã™ï¼ãŠãƒ‡ãƒ¼ãƒˆæ¥½ã—ã‚“ã§ãã ã•ã„â¤ï¸â€ğŸ”¥</td>\n",
       "      <td>2022-10-01_00:59:50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>db215c78c59027e4</td>\n",
       "      <td>1573305402208686081</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>åƒè‘‰ å¸‚å·å¸‚</td>\n",
       "      <td>city</td>\n",
       "      <td>æ—¥æœ¬</td>\n",
       "      <td>139.885492</td>\n",
       "      <td>35.655568</td>\n",
       "      <td>139.976610</td>\n",
       "      <td>35.775796</td>\n",
       "      <td>533937</td>\n",
       "      <td>533935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69884</th>\n",
       "      <td>74427</td>\n",
       "      <td>95</td>\n",
       "      <td>ä»Šæ—¥ã® #å¤•æš®ã‚Œ ã¯ãªã‚“ã¨ã‚‚å¿ƒå‹•ã‹ã•ã‚Œã‚‹è‰²åˆã„ã ã£ãŸã€‚é‰„å¡”ã‚‚ã„ã„æ„Ÿã˜ã«æ’®ã‚ŒãŸ / today...</td>\n",
       "      <td>2022-10-31_23:57:58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1ea0fd1a31366833</td>\n",
       "      <td>7199952.0</td>\n",
       "      <td>...</td>\n",
       "      <td>æ¨ªæµœå¸‚</td>\n",
       "      <td>ç¥å¥ˆ æ¨ªæµœå¸‚ éƒ½ç­‘åŒº</td>\n",
       "      <td>city</td>\n",
       "      <td>æ—¥æœ¬</td>\n",
       "      <td>139.543097</td>\n",
       "      <td>35.507956</td>\n",
       "      <td>139.616102</td>\n",
       "      <td>35.566753</td>\n",
       "      <td>533924</td>\n",
       "      <td>533914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69885</th>\n",
       "      <td>74428</td>\n",
       "      <td>96</td>\n",
       "      <td>ãŠå°å ´ Tokyoã«å†™çœŸã‚’æŠ•ç¨¿ã—ã¾ã—ãŸhttps://t.co/GJcY9s06SY</td>\n",
       "      <td>2022-10-31_23:57:57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>594fa6c6bc5b5ba9</td>\n",
       "      <td>110322291.0</td>\n",
       "      <td>...</td>\n",
       "      <td>æ—¥æœ¬ æ±äº¬</td>\n",
       "      <td>æ±äº¬ æ¸¯åŒº</td>\n",
       "      <td>city</td>\n",
       "      <td>æ—¥æœ¬</td>\n",
       "      <td>139.708754</td>\n",
       "      <td>35.622973</td>\n",
       "      <td>139.782004</td>\n",
       "      <td>35.682605</td>\n",
       "      <td>533935</td>\n",
       "      <td>533935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69886</th>\n",
       "      <td>74429</td>\n",
       "      <td>97</td>\n",
       "      <td>ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ãŠ—ï¸ãŠ—ï¸ãŠ—ï¸ä½œå“ã€å¿…ãšæ‹è¦‹ã—ã¾ã™ğŸ‘€</td>\n",
       "      <td>2022-10-31_23:57:55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bcf7dca0cae1c2e6</td>\n",
       "      <td>1088408401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ç¥å¥ˆ æ¨ªæµœå¸‚ å—åŒº</td>\n",
       "      <td>city</td>\n",
       "      <td>æ—¥æœ¬</td>\n",
       "      <td>139.570896</td>\n",
       "      <td>35.406284</td>\n",
       "      <td>139.641197</td>\n",
       "      <td>35.441318</td>\n",
       "      <td>533904</td>\n",
       "      <td>533944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69887</th>\n",
       "      <td>74430</td>\n",
       "      <td>98</td>\n",
       "      <td>ã“ã‚Œã«ã¤ãã¾ã—ã¦ã€ä¿ºã®ãƒ—ãƒ­ãƒ¬ã‚¹ãƒ‡ãƒ“ãƒ¥ãƒ¼ã®æ™‚ã€æ„Ÿæ¥µã¾ã‚‹äººã„ãŸã ã‚ã†ã‹â€¦ğŸ¤£ç¬‘ã„ã—ã‹èµ·ããªã‹ã£ãŸæ§˜...</td>\n",
       "      <td>2022-10-31_23:57:55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a398e1f1025abe37</td>\n",
       "      <td>814713932.0</td>\n",
       "      <td>...</td>\n",
       "      <td>æ±äº¬ åŒ—åŒº</td>\n",
       "      <td>åŸ¼ç‰ æ˜¥æ—¥éƒ¨å¸‚</td>\n",
       "      <td>city</td>\n",
       "      <td>æ—¥æœ¬</td>\n",
       "      <td>139.707880</td>\n",
       "      <td>35.935390</td>\n",
       "      <td>139.832566</td>\n",
       "      <td>36.043504</td>\n",
       "      <td>533975</td>\n",
       "      <td>533945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69888</th>\n",
       "      <td>74431</td>\n",
       "      <td>99</td>\n",
       "      <td>ãµãƒ¼ã‚€ã€‚ã€‚ã€‚å›½å‹¢èª¿æŸ»ã®æ™‚ã«èª¿ã¹ç›´ã—ã¦ã»ã—ã„ğŸ˜³</td>\n",
       "      <td>2022-10-31_23:57:54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>f7c22e0cf7b3af2b</td>\n",
       "      <td>139970384.0</td>\n",
       "      <td>...</td>\n",
       "      <td>æ±äº¬éƒ½</td>\n",
       "      <td>æ±äº¬ æ¸‹è°·åŒº</td>\n",
       "      <td>city</td>\n",
       "      <td>æ—¥æœ¬</td>\n",
       "      <td>139.661368</td>\n",
       "      <td>35.641564</td>\n",
       "      <td>139.723884</td>\n",
       "      <td>35.692138</td>\n",
       "      <td>533935</td>\n",
       "      <td>533945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69889 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1 Unnamed: 0  \\\n",
       "0                 0          0   \n",
       "1                 1          1   \n",
       "2                 2          2   \n",
       "3                 3          3   \n",
       "4                 4          4   \n",
       "...             ...        ...   \n",
       "69884         74427         95   \n",
       "69885         74428         96   \n",
       "69886         74429         97   \n",
       "69887         74430         98   \n",
       "69888         74431         99   \n",
       "\n",
       "                                                    text           created_at  \\\n",
       "0                                     ãã‚Œã‚‚è‰¯ã„ã‘ã©ãƒ­ãƒªãƒ‡è¡Œã“ã†ã‚ˆğŸ°ğŸ‘—ğŸ¤´ğŸ‘¸  2022-10-01_00:59:57   \n",
       "1                                             å„ªè‰¯ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã•ã‚“ğŸ¥‡  2022-10-01_00:59:54   \n",
       "2            ã“ã“æœ€è¿‘ãšã£ã¨ãƒã‚¬ãƒ†ã‚£ãƒ–ã¨ãƒã‚¸ãƒ†ã‚£ãƒ–ãŒæˆ¦ã£ã¦ã¦ã€ã‚„ã£ã¨ãƒã‚¸ãƒ†ã‚£ãƒ–ãŒå‹ã¡ã‚‚ã†ã—ãŸï¼æ‹æ‰‹ï¼  2022-10-01_00:59:53   \n",
       "3                                       æœ‰è­˜è€…ãŒæ•™ãˆã¦ãã‚ŒãŸã‚‰ã„ã„ãªãw  2022-10-01_00:59:52   \n",
       "4                             ã”ç„¡äº‹ã§ä½•ã‚ˆã‚Šã§ã™ï¼ãŠãƒ‡ãƒ¼ãƒˆæ¥½ã—ã‚“ã§ãã ã•ã„â¤ï¸â€ğŸ”¥  2022-10-01_00:59:50   \n",
       "...                                                  ...                  ...   \n",
       "69884  ä»Šæ—¥ã® #å¤•æš®ã‚Œ ã¯ãªã‚“ã¨ã‚‚å¿ƒå‹•ã‹ã•ã‚Œã‚‹è‰²åˆã„ã ã£ãŸã€‚é‰„å¡”ã‚‚ã„ã„æ„Ÿã˜ã«æ’®ã‚ŒãŸ / today...  2022-10-31_23:57:58   \n",
       "69885         ãŠå°å ´ Tokyoã«å†™çœŸã‚’æŠ•ç¨¿ã—ã¾ã—ãŸhttps://t.co/GJcY9s06SY  2022-10-31_23:57:57   \n",
       "69886                        ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ãŠ—ï¸ãŠ—ï¸ãŠ—ï¸ä½œå“ã€å¿…ãšæ‹è¦‹ã—ã¾ã™ğŸ‘€  2022-10-31_23:57:55   \n",
       "69887  ã“ã‚Œã«ã¤ãã¾ã—ã¦ã€ä¿ºã®ãƒ—ãƒ­ãƒ¬ã‚¹ãƒ‡ãƒ“ãƒ¥ãƒ¼ã®æ™‚ã€æ„Ÿæ¥µã¾ã‚‹äººã„ãŸã ã‚ã†ã‹â€¦ğŸ¤£ç¬‘ã„ã—ã‹èµ·ããªã‹ã£ãŸæ§˜...  2022-10-31_23:57:55   \n",
       "69888                             ãµãƒ¼ã‚€ã€‚ã€‚ã€‚å›½å‹¢èª¿æŸ»ã®æ™‚ã«èª¿ã¹ç›´ã—ã¦ã»ã—ã„ğŸ˜³  2022-10-31_23:57:54   \n",
       "\n",
       "       retweets  replies  likes quote_count          place_id  \\\n",
       "0           0.0      1.0    0.0           0  65b41c11aca77bdb   \n",
       "1           0.0      0.0    1.0           0  f1299e526e0cc34d   \n",
       "2           0.0      0.0    0.0           0  77173905596af4ab   \n",
       "3           0.0      0.0    2.0           0  4c1c4868f96634ed   \n",
       "4           0.0      1.0    1.0           0  db215c78c59027e4   \n",
       "...         ...      ...    ...         ...               ...   \n",
       "69884       0.0      0.0    2.0         0.0  1ea0fd1a31366833   \n",
       "69885       0.0      0.0    0.0         0.0  594fa6c6bc5b5ba9   \n",
       "69886       0.0      1.0    1.0         0.0  bcf7dca0cae1c2e6   \n",
       "69887       0.0      0.0    1.0         0.0  a398e1f1025abe37   \n",
       "69888       0.0      2.0    3.0         0.0  f7c22e0cf7b3af2b   \n",
       "\n",
       "                 author_id  ... author_location   city_name object country  \\\n",
       "0               4843678447  ...      ãƒ‡ã‚£ã‚ºãƒ‹ãƒ¼ãƒ©ãƒ³ãƒ‰è¿‘è¾º      åƒè‘‰ æµ¦å®‰å¸‚   city      æ—¥æœ¬   \n",
       "1      1312247388745023488  ...             NaN      åƒè‘‰ ä½å€‰å¸‚   city      æ—¥æœ¬   \n",
       "2                449521349  ...             NaN      æ±äº¬ æ–‡äº¬åŒº   city      æ—¥æœ¬   \n",
       "3      1060387314369683456  ...              æ±äº¬      æ±äº¬ æ±Ÿæ±åŒº   city      æ—¥æœ¬   \n",
       "4      1573305402208686081  ...             NaN      åƒè‘‰ å¸‚å·å¸‚   city      æ—¥æœ¬   \n",
       "...                    ...  ...             ...         ...    ...     ...   \n",
       "69884            7199952.0  ...             æ¨ªæµœå¸‚  ç¥å¥ˆ æ¨ªæµœå¸‚ éƒ½ç­‘åŒº   city      æ—¥æœ¬   \n",
       "69885          110322291.0  ...           æ—¥æœ¬ æ±äº¬       æ±äº¬ æ¸¯åŒº   city      æ—¥æœ¬   \n",
       "69886         1088408401.0  ...             NaN   ç¥å¥ˆ æ¨ªæµœå¸‚ å—åŒº   city      æ—¥æœ¬   \n",
       "69887          814713932.0  ...           æ±äº¬ åŒ—åŒº     åŸ¼ç‰ æ˜¥æ—¥éƒ¨å¸‚   city      æ—¥æœ¬   \n",
       "69888          139970384.0  ...             æ±äº¬éƒ½      æ±äº¬ æ¸‹è°·åŒº   city      æ—¥æœ¬   \n",
       "\n",
       "      UserPlase_longitude UserPlase_latitude UserPlase_sub_longitude  \\\n",
       "0              139.872407          35.616612              139.939631   \n",
       "1              140.126120          35.624589              140.301034   \n",
       "2              139.717275          35.699474              139.772477   \n",
       "3              139.771307          35.582057              139.849007   \n",
       "4              139.885492          35.655568              139.976610   \n",
       "...                   ...                ...                     ...   \n",
       "69884          139.543097          35.507956              139.616102   \n",
       "69885          139.708754          35.622973              139.782004   \n",
       "69886          139.570896          35.406284              139.641197   \n",
       "69887          139.707880          35.935390              139.832566   \n",
       "69888          139.661368          35.641564              139.723884   \n",
       "\n",
       "      UserPlase_sub_latitude    code  Tokyo_code_estimate  \n",
       "0                  35.672793  533936               533945  \n",
       "1                  35.766545  534031               533934  \n",
       "2                  35.735929  533945               533945  \n",
       "3                  35.708066  533926               533934  \n",
       "4                  35.775796  533937               533935  \n",
       "...                      ...     ...                  ...  \n",
       "69884              35.566753  533924               533914  \n",
       "69885              35.682605  533935               533935  \n",
       "69886              35.441318  533904               533944  \n",
       "69887              36.043504  533975               533945  \n",
       "69888              35.692138  533935               533945  \n",
       "\n",
       "[69889 rows x 24 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Tokyo_adEstimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Tokyo_adEstimate.to_csv('/home/is/shuntaro-o/dev/persons_move_analysis/data/use_new_model/202210_1month_per_hour_ad_estimate.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('SharedTask')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6feaf4af813783365efc585a6800850988678764fcb0bba12eca45fe4d31fdb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
